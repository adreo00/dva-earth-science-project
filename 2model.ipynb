{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, confusion_matrix, precision_recall_curve, PrecisionRecallDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import label_binarize, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"./output\"\n",
    "VIZ_DIR = \"./Visualization\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confusion matrix (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(key_list, col_name, model_name, X_test, y_test, model, pred):\n",
    "    confusion_matrix(y_test, pred)\n",
    "    # accuracy_score(y_test,optyts_knnpred ) #0.8487394957983193\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.set_title('Confusion Matrix: ' + col_name + \", \" + model_name)\n",
    "    disp = metrics.plot_confusion_matrix(model, X_test, y_test, display_labels=key_list, ax=ax)\n",
    "    disp.confusion_matrix\n",
    "\n",
    "    plt.savefig(f\"{OUTPUT_DIR}/confusion_matrix_\" + col_name + \"_\" + model_name + \".png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Precison Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall(key_list, col_name, model_name, X, y, X_test, y_test, model, pred, use_SMOTE = True):\n",
    "    n_classes = 5\n",
    "    if model_name.lower() in [\"knn\", \"random forest\"]:\n",
    "        y_score = np.array(model.predict_proba(X_test))[:, :, 1].T\n",
    "    else: \n",
    "        y_score = model.predict_proba(X_test)\n",
    "\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    for i in range(0, n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_score[:, i])\n",
    "        average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])\n",
    "\n",
    "    # A \"micro-average\": quantifying score on all classes jointly\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test.ravel(), y_score.ravel())\n",
    "    average_precision[\"micro\"] = average_precision_score(y_test, y_score, average=\"micro\")\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(7, 8))\n",
    "\n",
    "    display = PrecisionRecallDisplay(\n",
    "        recall=recall[\"micro\"],\n",
    "        precision=precision[\"micro\"],\n",
    "        average_precision=average_precision[\"micro\"],\n",
    "    )\n",
    "    display.plot(ax=ax, name=\"Average precision-recall\", color=\"gold\")\n",
    "\n",
    "    colors = cycle([\n",
    "        mpl.colors.to_hex([141/255,160/255,203/255,.5], keep_alpha=True),\n",
    "        mpl.colors.to_hex([231/255,138/255,195/255,.5], keep_alpha=True),\n",
    "        mpl.colors.to_hex([255/255,217/255,47/255,.5], keep_alpha=True),\n",
    "        mpl.colors.to_hex([252/255,141/255,98/255,.5], keep_alpha=True),\n",
    "        mpl.colors.to_hex([102/255,194/255,165/255,.5], keep_alpha=True),\n",
    "    ])\n",
    "\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    \n",
    "    class_name_dict = {\n",
    "        0: \"HB\",\n",
    "        1:\"ICEQUAKE\",\n",
    "        2:\"LP\",\n",
    "        3: \"REGIONAL\",\n",
    "        4:\"VT\", \n",
    "    }\n",
    "\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        display = PrecisionRecallDisplay(\n",
    "            recall=recall[i],\n",
    "            precision=precision[i],\n",
    "            average_precision=average_precision[i],\n",
    "        )\n",
    "        class_name = class_name_dict[i]\n",
    "        display.plot(ax=ax, name=f\"{class_name}\", color=color)\n",
    "\n",
    "    # add the legend for the iso-f1 curves\n",
    "    handles, labels = display.ax_.get_legend_handles_labels()\n",
    "\n",
    "    # set the legend and the axes\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.legend(handles=handles, labels=labels, loc=\"best\")\n",
    "    if use_SMOTE:\n",
    "        ax.set_title(col_name + \", \" + model_name + \": Precision-Recall curve (with SMOTE)\")\n",
    "        plt.savefig(f\"{OUTPUT_DIR}/precision_recall_\" + col_name + \"_\" + model_name + \"_SMOTE.png\", facecolor='white', transparent=False)\n",
    "    else:\n",
    "        ax.set_title(col_name + \", \" + model_name + \": Precision-Recall curve (without SMOTE)\")\n",
    "        plt.savefig(f\"{OUTPUT_DIR}/precision_recall_\" + col_name + \"_\" + model_name + \".png\", facecolor='white', transparent=False)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Results Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResultsTemplate(MicSigV1):\n",
    "    KeepCols = ['Year', 'Month', 'Type', 'Duration']\n",
    "    template = MicSigV1.copy().loc[:, KeepCols]\n",
    "    columns = ['Cleaning', 'KNN', 'SVM', 'RF', 'KMs', 'LR']\n",
    "    template[columns] = None\n",
    "    template.head()\n",
    "\n",
    "    return template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(key_list, col_name, X, y, X_train, X_test, y_train, y_test, use_SMOTE):\n",
    "    # Knn Model\n",
    "    no_neighbors = np.arange(2, 50, 5)\n",
    "    accuracy_knn = np.zeros((no_neighbors.shape[0]))\n",
    "    k = 0\n",
    "    for knn in no_neighbors:\n",
    "        knn_model = KNeighborsClassifier(n_neighbors=knn).fit(X_train, y_train)\n",
    "        yts_knnpred = knn_model.predict(X_test)  # confusion_matrix(y_train, y_pred)\n",
    "        accuracy_knn[k] = accuracy_score(y_test, yts_knnpred)\n",
    "        k += 1\n",
    "    opt_knn = no_neighbors[np.argmax(accuracy_knn)]\n",
    "    optknn_model = KNeighborsClassifier(n_neighbors=opt_knn).fit(X_train, y_train)\n",
    "    optyts_knnpred = knn_model.predict(X_test)\n",
    "\n",
    "    #plot_confusion_matrix(key_list, col_name, \"kNN\", X_test, y_test, optknn_model, optyts_knnpred)\n",
    "    plot_precision_recall(key_list, col_name, \"kNN\", X, y, X_test, y_test, optknn_model, optyts_knnpred, use_SMOTE)\n",
    "\n",
    "    return knn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeans(X, y, use_SMOTE):\n",
    "    km_model = KMeans(n_clusters=5, random_state=42).fit_predict(X)\n",
    "    confusion_matrix(y, km_model)\n",
    "    accuracy_score(y, km_model)  # 0.2384161752316765\n",
    "\n",
    "    return km_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(key_list, col_name, X, y, X_train, X_test, y_train, y_test, use_SMOTE):\n",
    "    rf_model = RandomForestClassifier(n_estimators=1000, random_state=42).fit(X_train, y_train)\n",
    "    yts_rf = rf_model.predict(X_test)\n",
    "\n",
    "    #plot_confusion_matrix(key_list, col_name, \"Random Forest\", X_test, y_test, rf_model, yts_rf)\n",
    "    plot_precision_recall(key_list, col_name, \"Random Forest\", X, y, X_test, y_test, rf_model, yts_rf, use_SMOTE)\n",
    "\n",
    "    return rf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(key_list, col_name, X, y, X_train, X_test, y_train, y_test, use_SMOTE):\n",
    "    y_train_de_encode = np.argmax(y_train, axis=1)\n",
    "    svm_model = SVC(gamma='auto', decision_function_shape='ovo', probability=True).fit(X_train, y_train_de_encode)\n",
    "    yts_svm = svm_model.predict(X_test)\n",
    "\n",
    "    #plot_confusion_matrix(key_list, col_name, \"SVM\", X_test, y_test, svm_model, yts_svm)\n",
    "    plot_precision_recall(key_list=key_list, col_name=col_name, model_name=\"SVM\", X=X, y=y,  X_test=X_test, y_test=y_test, model=svm_model, pred=yts_svm, use_SMOTE=use_SMOTE)\n",
    "\n",
    "    return svm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(key_list, col_name, X, y, X_train, X_test, y_train, y_test, use_SMOTE):\n",
    "    y_train_decode = np.argmax(y_train, axis=1)\n",
    "    lr = linear_model.LogisticRegression(multi_class='ovr', max_iter=1000).fit(X_train, y_train_decode)\n",
    "    yts_lr = lr.predict(X_test)\n",
    "\n",
    "    y_test_decode = np.argmax(y_test, axis=1)\n",
    "    accuracy_score(y_test_decode, yts_lr)  # 0.8529411764705882\n",
    "\n",
    "    #plot_confusion_matrix(key_list, col_name, \"Logistic Regression\", X_test, y_test, lr, yts_lr)\n",
    "    plot_precision_recall(key_list, col_name, \"Logistic Regression\", X, y, X_test, y_test, lr, yts_lr, use_SMOTE)\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs all models, generates plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_models(MicSigV1, use_SMOTE = False):\n",
    "    label_encoder = LabelEncoder()\n",
    "    MicSigV1['Type'] = MicSigV1['Type'].astype('str')\n",
    "    MicSigV1['Type_CatNbr'] = label_encoder.fit_transform((MicSigV1['Type'].values))\n",
    "    Type_Mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    key_list = [key for key in Type_Mapping.keys()]\n",
    "\n",
    "    results_template = ResultsTemplate(MicSigV1)\n",
    "    y = MicSigV1['Type_CatNbr']\n",
    "\n",
    "    iterations = ['Raw', '2', '4', '6']\n",
    "    results_list = []\n",
    "    for curr_iter in iterations:\n",
    "        # 3 dimensions: the Maximum Threshold Frequency (20-30 Hz), D1 Max. peak in freq.-domain, Entropy\n",
    "        X = MicSigV1[[\"Freq_\" + curr_iter, \"D1_Max_\" + curr_iter, \"E_\" + curr_iter]]\n",
    "\n",
    "        # Classification Model - Normalized Raw Data\n",
    "        # Split the data\n",
    "        X_res, y_res = X, y\n",
    "        if use_SMOTE:\n",
    "            smt = SMOTETomek(random_state=42)\n",
    "            X_res, y_res = smt.fit_resample(X, y)\n",
    "        Y_enc = label_binarize(y_res, classes=y.unique().tolist())\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_res, Y_enc, test_size=0.2, random_state=0)\n",
    "\n",
    "        knn_model = knn(key_list, curr_iter, X, y, X_train, X_test, y_train, y_test, use_SMOTE)\n",
    "        svm_model = svm(key_list, curr_iter, X, y, X_train, X_test, y_train, y_test, use_SMOTE)\n",
    "        rf_model = random_forest(key_list, curr_iter, X, y, X_train, X_test, y_train, y_test, use_SMOTE)\n",
    "        km_model = kMeans(X, y, use_SMOTE)\n",
    "        lr = logistic_regression(key_list, curr_iter, X, y, X_train, X_test, y_train, y_test, use_SMOTE)\n",
    "\n",
    "        results_df = results_template.copy()\n",
    "        results_df['Cleaning'] = curr_iter\n",
    "        results_df['KNN'] = knn_model.predict(X)\n",
    "        results_df['SVM'] = svm_model.predict(X)\n",
    "        results_df['RF'] = rf_model.predict(X)\n",
    "        results_df['KMs'] = km_model\n",
    "        results_df['LR'] = lr.predict(X)\n",
    "        id_vars = ['Year', 'Month', 'Type', 'Duration', 'Cleaning']\n",
    "\n",
    "        # Cast data into long form\n",
    "        results_df = pd.melt(results_df, id_vars=id_vars, var_name='Model', value_name='Prediction')\n",
    "\n",
    "        # Convert encoded labels to strings\n",
    "        results_df.Prediction = results_df.Prediction.apply(lambda x: label_encoder.inverse_transform([x])[0])\n",
    "\n",
    "        results_list.append(results_df)\n",
    "\n",
    "    Output = pd.concat(results_list)\n",
    "    Output = Output.reset_index()\n",
    "    Output = Output.rename(columns={'index': 'EQ'})\n",
    "    Output[\"Correct Prediction\"] = Output[\"Type\"]== Output[\"Prediction\"]\n",
    "    if use_SMOTE:\n",
    "        smote_name = \"SMOTE\"\n",
    "    else:\n",
    "        smote_name = \"WITHOUT_SMOTE\"\n",
    "    Output.to_csv(f'{VIZ_DIR}/classification_results_{smote_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1624/398049879.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MicSigV1['Type'].loc[ind[0]] = \"REGIONAL\"\n",
      "/tmp/ipykernel_1624/398049879.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MicSigV1['Type'].loc[ind2[0]] = \"LP\"\n",
      "/tmp/ipykernel_1624/398049879.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MicSigV1['Type'].loc[ind3[0]] = \"VT\"\n",
      "/tmp/ipykernel_1624/2603435087.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  _, ax = plt.subplots(figsize=(7, 8))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_file = './clean_data.parquet'\n",
    "MicSigV1 = pd.read_parquet(input_file)\n",
    "\n",
    "\n",
    "# Cleaning data\n",
    "ind = np.where(MicSigV1['Type'] == '''['REGIONAL']''')\n",
    "ind2 = np.where(MicSigV1['Type'] == '''['LP']''')\n",
    "ind3 = np.where(MicSigV1['Type'] == '''VT ''')\n",
    "MicSigV1['Type'].loc[ind[0]] = \"REGIONAL\"\n",
    "MicSigV1['Type'].loc[ind2[0]] = \"LP\"\n",
    "MicSigV1['Type'].loc[ind3[0]] = \"VT\"\n",
    "\n",
    "#generate output dirs\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "if not os.path.exists(VIZ_DIR):\n",
    "    os.mkdir(VIZ_DIR)\n",
    "\n",
    "generate_models(MicSigV1, use_SMOTE = False)\n",
    "generate_models(MicSigV1, use_SMOTE = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
